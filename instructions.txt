# Project Update Plan: Adapt to Actuals Data and USDA Mapping

**Goal:** Modify the VectorDB project to work with transaction data from `data/Actuals/`, embed only transaction descriptions, and evaluate similarity search results against the USDA mapping ground truth in `data/Actuals/Corrected_mapping.xlsx`.

**Steps:**

1.  **Analyze Data Structures:** [COMPLETED]
    *   Identify the transaction report file(s) within `data/Actuals/`. Determine relevant sheet names and the exact column name containing the product descriptions to be used.
    *   Examine `data/Actuals/Corrected_mapping.xlsx`: Determine the sheet name and the exact column names for the 'Transaction Description' and the 'USDA Description'.

2.  **Update Data Processing (`src/data_processing.py`):** [COMPLETED]
    *   Modify `load_transaction_data` (or create a new function) to specifically read the transaction report identified in Step 1.
    *   Adjust `process_transaction_data` to:
        *   Extract only the relevant product description column.
        *   Handle any necessary cleaning (e.g., stripping whitespace, lowercasing).
        *   Return a DataFrame containing *only* the unique, cleaned transaction product descriptions. Remove aggregation logic for price/quantity if no longer needed.

3.  **Update Embedding Logic (`src/vectordb.py`):** [COMPLETED]
    *   Modify `ProductEmbedder`:
        *   Remove the logic for creating "enhanced" descriptions (text + price + quantity).
        *   Ensure `embed_products` and `embed_query` work directly with the plain text descriptions.
    *   Modify `ProductVectorDB.add_products_to_db`:
        *   Ensure it expects and correctly processes the DataFrame of unique transaction descriptions from the updated `process_transaction_data`.
        *   Store the transaction description itself as metadata (e.g., under the key 'product_description').
    *   Update `create_product_vector_db`:
        *   Ensure it calls the updated `process_transaction_data`.
        *   Ensure it passes the correct data (unique transaction descriptions DataFrame) to `add_products_to_db`.

4.  **Update Evaluation Logic (`analysis/bidirectional_similarity.py`):** [COMPLETED]
    *   Modify `test_bidirectional_similarity`:
        *   Update parameter defaults or documentation to reflect that the ground truth file is now `Corrected_mapping.xlsx`.
        *   Load the ground truth map linking 'Transaction Description' (normalized) to 'USDA Description' (normalized, dashes removed).
        *   **Revise Precision/Recall Calculation:**
            *   The `query` is a `query_transaction_desc`.
            *   The `results` contain `predicted_transaction_desc`.
            *   **Lookup:** For the `query_transaction_desc`, find its `true_usda_desc` from the ground truth map.
            *   **Comparison Loop:** For each `predicted_transaction_desc` in the results:
                *   Look up *its* `predicted_usda_desc` from the ground truth map.
                *   If `predicted_usda_desc` matches `true_usda_desc`, increment `current_tp`.
                *   If `predicted_usda_desc` does *not* match `true_usda_desc` (but was found in the map), increment `current_fp`.
            *   **False Negatives:** After checking all predictions, if no `predicted_usda_desc` matched `true_usda_desc`, increment `current_fn` by 1 for the query.
        *   Aggregate `total_tp`, `total_fp`, `total_fn` across all queries and calculate final metrics.

5.  **Update Test Runner (`analysis/run_bidirectional_test.py`):** [COMPLETED]
    *   Ensure `create_product_vector_db` is called appropriately to build the DB from the new transaction data.
    *   Modify the call to `test_bidirectional_similarity`:
        *   Ensure `test_queries` is populated with the unique transaction descriptions from the database.
        *   Update the `ground_truth_*` arguments to point to the correct columns and sheet in `data/Actuals/Corrected_mapping.xlsx` (using `src.config` constants).

6.  **Update Configuration (`src/config.py`):** [COMPLETED]
    *   Add/Update constants for the new transaction file path(s), sheet names, and column names.
    *   Update `GROUND_TRUTH_EXCEL_PATH`, `GROUND_TRUTH_SHEET_NAME`, `GROUND_TRUTH_QUERY_COLUMN` (should now be the transaction description column in the mapping file), and `GROUND_TRUTH_MATCH_COLUMN` (should now be the USDA description column in the mapping file).

7.  **Run Final Test & Analyze Results:** [COMPLETED]
    *   Successfully ran comprehensive evaluation on all 14,777 unique products.
    *   Analyzed results from full bidirectional similarity test:
        * Products with valid USDA codes: 120 of 14,777
        * Total bidirectional matches returned: 600
        * Correct matches found: 49
        * Precision: 0.0817 (8.17%)
        * Recall: 0.4083 (40.83%)
        * F1 Score: 0.1361 (13.61%)
    *   Examined detailed results in `analysis_results/bidirectional_evaluation_results.csv`.

8.  **Performance Improvement Plan:**
    *   **Threshold Optimization:**
        * Current forward threshold (0.25) and backward threshold (0.20) favor recall over precision.
        * Consider increasing both thresholds incrementally (e.g., to 0.35/0.30) to improve precision at the cost of some recall.
        * Test multiple threshold combinations and track the F1 score to find optimal balance.
    *   **Embedding Model Improvement:**
        * Test more advanced embedding models from sentence-transformers:
            * `all-mpnet-base-v2` (better quality but slower)
            * `paraphrase-multilingual-mpnet-base-v2` (better for food items with regional naming variations)
        * Update the `EMBEDDING_MODEL` in `src/config.py` to experiment with alternatives.
    *   **Data Quality Enhancement:**
        * Address the limited ground truth data (only 120 of 14,777 products have USDA mappings).
        * Expand the `Corrected_mapping.xlsx` file with additional validated mappings.
        * Consider data augmentation techniques to generate more varied product descriptions for existing mappings.
    *   **Evaluation Methodology:**
        * Create a targeted test set that focuses only on products with USDA codes for more meaningful evaluation.
        * Implement k-fold cross-validation to ensure robustness of performance metrics.
        * Consider weighted scoring that prioritizes common or important food items.
    *   **Code Optimization:**
        * Refactor `find_similar_products_bidirectional` to improve processing speed for large-scale analysis.
        * Add caching mechanism for embeddings to prevent redundant calculations.
        * Implement parallel processing for bidirectional similarity checks when evaluating large datasets.
